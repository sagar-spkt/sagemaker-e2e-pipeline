{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install the AWS Command Line Interface (CLI), which is used to interact with various AWS services from the command line.\n",
    "```shell\n",
    "curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\"\n",
    "unzip awscliv2.zip\n",
    "sudo ./aws/install\n",
    "```\n",
    "\n",
    "Setup default AWS credentials and region. This step configures the default AWS credentials and region for the CLI. It prompts you to enter the Access Key ID, Secret Access Key, default region name, and default output format.\n",
    "\n",
    "```shell\n",
    "aws configure\n",
    "```\n",
    "\n",
    "Enter your credentials and default AWS region. For example:\n",
    "```mathematica\n",
    "AWS Access Key ID [None]: AKIAIOSFODNN7EXAMPLE\n",
    "AWS Secret Access Key [None]: wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\n",
    "Default region name [None]: us-east-1\n",
    "Default output format [None]:\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure your AWS credentials have full access to following AWS resources that are used in the pipeline:\n",
    "- AWS App Autoscaling: This resource is used for automatically scaling AWS resources based on defined policies.\n",
    "- AWS EventBridge(Previously Cloudwatch Event): This resource is used for monitoring and responding to Sagemaker Model Registry events.\n",
    "- AWS Elastic Container Registry(ECR): This resource is used for storing Docker container images used in the pipeline.\n",
    "- AWS IAM Role/Policies: This resource is used for defining and managing access permissions for AWS services used by various components in the pipeline.\n",
    "- AWS Lambda Function: This resource is used for handling various events in pipeline, e.g., deployment and  of endpoint.\n",
    "- AWS S3: This resource is used for storing input and output data for the pipeline.\n",
    "- AWS Sagemaker: This resource is the main service used for training and deploying machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Terraform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Terraform, an infrastructure as code tool, which will be used to create and manage the AWS resources required for the pipeline. For linux, you can use following instructions. For other platforms refer official terraform installation instructions.\n",
    "```shell\n",
    "sudo apt-get update && sudo apt-get install -y gnupg software-properties-common\n",
    "wget -O- https://apt.releases.hashicorp.com/gpg | \\\n",
    "gpg --dearmor | \\\n",
    "sudo tee /usr/share/keyrings/hashicorp-archive-keyring.gpg\n",
    "gpg --no-default-keyring \\\n",
    "--keyring /usr/share/keyrings/hashicorp-archive-keyring.gpg \\\n",
    "--fingerprint\n",
    "echo \"deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] \\\n",
    "https://apt.releases.hashicorp.com $(lsb_release -cs) main\" | \\\n",
    "sudo tee /etc/apt/sources.list.d/hashicorp.list\n",
    "sudo apt update\n",
    "sudo apt-get install terraform\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Installs Docker, a containerization platform, which will be used to build and run Docker containers for preprocessing, training, evaluation, and inference in the pipeline. For linux, you can use the following set of commands. For other platforms, refer official docker installation instructions.\n",
    "```shell\n",
    "sudo apt-get update\n",
    "sudo apt-get install ca-certificates curl gnupg\n",
    "sudo install -m 0755 -d /etc/apt/keyrings\n",
    "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n",
    "sudo chmod a+r /etc/apt/keyrings/docker.gpg\n",
    "echo \\\n",
    "  \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n",
    "  \"$(. /etc/os-release && echo \"$VERSION_CODENAME\")\" stable\" | \\\n",
    "  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n",
    "sudo apt-get update\n",
    "sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n",
    "sudo usermod -aG docker ${USER}\n",
    "su - ${USER}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clone the Repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone the Git repository that contains the source code and configuration files for the SageMaker end-to-end pipeline.\n",
    "```shell\n",
    "git clone https://github.com/sagar-spkt/sagemaker-e2e-pipeline.git\n",
    "cd sagemaker-e2e-pipeline\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create virtual environment and install required dependencies from `requirements.txt`\n",
    "```shell\n",
    "python3 -m venv venv\n",
    "source venv/bin/activate\n",
    "pip install -r requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AWS Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Terraform and apply the Terraform configuration to create the AWS resources needed for the pipeline. The provided variables specify the pipeline name, AWS region, instance types for preprocessing, training, evaluation, and inference, and the maximum number of endpoint instances. Adjust these variables as needed for your specific requirements.\n",
    "```shell\n",
    "terraform init\n",
    "terraform apply \\\n",
    "-var pipeline-name=\"sklearn-multimodel\" \\\n",
    "-var aws-region=\"us-east-1\" \\\n",
    "-var preprocessing-instance=\"ml.t3.xlarge\" \\\n",
    "-var training-instance=\"ml.m5.large\" \\\n",
    "-var evaluation-instance=\"ml.t3.xlarge\" \\\n",
    "-var inference-instance=\"ml.m5.large\" \\\n",
    "-var max-endpoint-instances=4\n",
    "```\n",
    "\n",
    "**Note:** If you have use Sagemaker before in your account, it is possible that the default bucket for Sagemaker already exists and terraform throws error. In that case, you can import existing bucket configuration to terraform with the following command:\n",
    "```shell\n",
    "terraform import aws_s3_bucket.pipeline_bucket sagemaker-<YOUR_AWS_REGION>-<YOUR AWS ACCOUNT ID>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Pipeline With Sagemaker Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After terraform creates the required infrastructures, you can see the newly created pipeline under **Home**>**Pipelines**.\n",
    "![](images/image1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the pipeline and click the `Create execution` button. You'll see pop like below where you can input the parameters for pipeline execution. Give the execution a unique name and input other parameters and hit `Start` button. Following are the descriptions of the input parameters to the pipeline:\n",
    "- **DatasetName**: Name of the dataset against which the pipeline performs modeling\n",
    "- **StratifySplit**: Whether to perform stratified train/test split of the dataset\n",
    "- **TestSetSize**: Test set size to create.\n",
    "- **RandomState**: Seed used for random operation in the pipeline\n",
    "- **CrossValidationScorer**: Metric used to select best model during cross-validation\n",
    "- **MaxTuningJobs**: Maximum number of tuning jobs to run. Hyperparameter search strategy used in the pipeline is `Random Search`.\n",
    "- **MaxTuningParallelJobs**: Maximum parallel runs during hyperparameter tuning\n",
    "- **MetricForRegistrationThreshold**: Metric whose value is used to decide whether to register the model to registry or not.\n",
    "- **MinThesholdForRegisterMetric**: Minimum value for `MetricForRegistrationThreshold` the model should pass to be registered in the model registry.\n",
    "- **RegisterModelApprovalStatus**: Whether to automatically deploy the model to endpoint or not if it passes the `MetricForRegistrationThreshold` constraint.\n",
    "![](images/image2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the list of pipeline executions in the dashboard. You'll find information like the execution status, time taken, and many more.\n",
    "![](images/image3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While one execution is running, you can run as many other executions you like provided that you don't hit the services quota limit of the instances and other resources used by the pipeline.\n",
    "![](images/image4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you click the executions, you'll find a nice graph of pipeline steps with their dependency links, execution progress, and inputs, outputs, logs and other information for each steps. \n",
    "![](images/image5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pipeline execution completes, you'll find model groups for the respective dataset under **Home**>**Models**>**Model registry**. For each dataset, the pipeline creates model group in the registry with the name formatted as `<PIPELINE_NAME>-<DATASET_NAME>`.\n",
    "![](images/image6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the model groups, you'll find all the model version that has been registered in model registry for the group. The new version of the model will have wither status of `Pending` and `Approved` based on the value of the parameter `RegisterModelApprovalStatus` passed during pipeline execution.\n",
    "![](images/image7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluating the model version in order to decide whether to approve or reject the model, you can go to **Version#**>**Model Quality** and have a look at the model performance metrices. \n",
    "![](images/image8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the performance metrices, you can approve or reject the model version for deployment from **Version#**>**Actions**>**Update Status**.\n",
    "![](images/image9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approving or rejecting the model will trigger an EventBridge rule whose target is a Lambda function responsible for deploying the latest approved model from the model registry to the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Pipeline with Boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize sagemaker and s3 boto3 client. `s3_client` is required as it will be used to read best model evaluation results saved by the pipeline in s3 bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_name = \"sklearn-multimodel\"\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the pipeline parameters. Following code will return input parameters to the pipeline, their type, and if available the default value. Following are the descriptions of the input parameters to the pipeline:\n",
    "- **DatasetName**: Name of the dataset against which the pipeline performs modeling\n",
    "- **StratifySplit**: Whether to perform stratified train/test split of the dataset\n",
    "- **TestSetSize**: Test set size to create.\n",
    "- **RandomState**: Seed used for random operation in the pipeline\n",
    "- **CrossValidationScorer**: Metric used to select best model during cross-validation\n",
    "- **MaxTuningJobs**: Maximum number of tuning jobs to run. Hyperparameter search strategy used in the pipeline is `Random Search`.\n",
    "- **MaxTuningParallelJobs**: Maximum parallel runs during hyperparameter tuning\n",
    "- **MetricForRegistrationThreshold**: Metric whose value is used to decide whether to register the model to registry or not.\n",
    "- **MinThesholdForRegisterMetric**: Minimum value for `MetricForRegistrationThreshold` the model should pass to be registered in the model registry.\n",
    "- **RegisterModelApprovalStatus**: Whether to automatically deploy the model to endpoint or not if it passes the `MetricForRegistrationThreshold` constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "json.loads(sm_client.describe_pipeline(\n",
    "    PipelineName=pipeline_name\n",
    ")[\"PipelineDefinition\"])[\"Parameters\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline execution with the desired parameters. The pipeline creates individual model for each dataset. If no previous training for the dataset is done, it creates new model group in Sagemaker registry and if the model group already exists in the registry, model will be registered with new version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_start_resp = sm_client.start_pipeline_execution(\n",
    "    PipelineName=pipeline_name,\n",
    "    PipelineParameters=[\n",
    "        # specify dataset name on which to train the model\n",
    "        {'Name': 'DatasetName', 'Value': 'breast-cancer'},\n",
    "        {'Name': 'MaxTuningJobs', 'Value': '4'},\n",
    "        {'Name': 'MaxTuningParallelJobs', 'Value': '2'},\n",
    "        # pass `Approved` if you want to auto approve the model in registry for deployment\n",
    "        # if it meets the requirement for model registry\n",
    "        {'Name': 'RegisterModelApprovalStatus', 'Value': 'PendingManualApproval'},\n",
    "        # mention other parameters if you do not want to use default value for them\n",
    "    ],\n",
    ")\n",
    "pipeline_start_resp[\"PipelineExecutionArn\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check pipeline execution status. Possible state of pipeline execution are: `Executing`|`Stopping`|`Stopped`|`Failed`|`Succeeded`. Wait until the value for `PipelineExecutionStatus` in the response is `Succeeded` otherwise subsequent steps will raise error. If the pipeline execution fails in anyway, you can find find the region for failure in the response of the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client.describe_pipeline_execution(\n",
    "    PipelineExecutionArn=pipeline_start_resp[\"PipelineExecutionArn\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After pipeline execution status is `Succeeded`, you can extract the latest model package from the registry. Following code will raise error if `PipelineExecutionStatus` is not `Succeeded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response = sm_client.list_pipeline_execution_steps(\n",
    "    # replace the arn with the arn of a package whose performance you want to look and do approve/reject operation\n",
    "    PipelineExecutionArn=pipeline_start_resp[\"PipelineExecutionArn\"],\n",
    "    MaxResults=100,\n",
    "    SortOrder='Descending'\n",
    ")\n",
    "latest_model_package_arn = response[\"PipelineExecutionSteps\"][0][\"Metadata\"][\"RegisterModel\"][\"Arn\"]\n",
    "latest_model_package_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this arn, we can extract the model's evaluation metric that is stored in s3. Following code will return stringified json eval results. This json is prepared by `scripts/evaluate.py`. Refer to the evaluation code there if you want to know how these results were prepared.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_package_resp = sm_client.describe_model_package(ModelPackageName=latest_model_package_arn)\n",
    "model_eval_s3_path = model_package_resp[\"ModelMetrics\"][\"ModelQuality\"][\"Statistics\"][\"S3Uri\"]\n",
    "eval_results = s3_client.get_object(Bucket=model_eval_s3_path.split(\"/\")[2], Key=\"/\".join(model_eval_s3_path.split(\"/\")[3:]))[\"Body\"].read().decode('utf-8')\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the performance, you can approve or reject the model for deployment. If the pipeline is executed with auto approval status enabled, it will already be deployed in the endpoint and rejecting the model will revert the model used in endpoint to the last approved model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Approve the model\n",
    "sm_client.update_model_package(\n",
    "    ModelPackageArn=latest_model_package_arn,\n",
    "    ModelApprovalStatus='Approved',\n",
    "    ApprovalDescription='<Comment for approving the model>',\n",
    ")\n",
    "\n",
    "# Reject the model\n",
    "sm_client.update_model_package(\n",
    "    ModelPackageArn=latest_model_package_arn,\n",
    "    ModelApprovalStatus='Rejected',\n",
    "    ApprovalDescription='<Comment for rejecting the model>',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approving or rejecting the model will trigger an EventBridge rule whose target is a Lambda function responsible for deploying the latest approved model from the model registry to the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking the Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since all models are hosted in a single endpoint, we've to mention with which model to do the inference. All of these models are stored in a s3 bucket folder and Sagemaker downloads the requested model from that s3 location upon invocation if it is not already instantiated in the endpoint instances. The catch here is that with every new version deployed, the model name will be timestamped as shown in the screenshot below. For the enduser, it is not convenient to mention timestamped model name.\n",
    "![](images/image10.png)\n",
    "So, the map between the model group name(dataset name) and the latest model for that group is maintained in a JSON file and a lambda function is created that extracts latest model for the user requested model group and do the inference using sagemaker endpoint. We'll use its function url. The function url can be found using the following terraform command.\n",
    "```shell\n",
    "terraform output\n",
    "```\n",
    "Note the function url from the output of this command. The output will be in the following format:\n",
    "```mathematica\n",
    "function_url_endpoint = \"https://yugkwzcne3rop4meh2x3g32xbq0fbhrp.lambda-url.us-east-1.on.aws/\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Payload Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The payload to this function url is a json with the following format:\n",
    "```json\n",
    "{\n",
    "    \"model\": \"<PIPELINE_NAME>-<DATASET-NAME>\"\n",
    "    \"data\": \"<CSV DUMP WITHOUT HEADERS WHICH SATISFIES INPUT TO SKLEARN'S MODEL.PREDICT FUNCTION>\"\n",
    "}\n",
    "```\n",
    "Following function uses pandas and json libraries to prepare payload in python and use requests to make the `POST` request to the function url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def invoke_endpoint(function_url, pipeline_name, dataset, data):\n",
    "    model = f\"{pipeline_name}-{dataset}\"\n",
    "    data = pd.DataFrame(data).to_csv(index=None, header=None)\n",
    "    payload = json.dumps({\n",
    "        \"model\": model,\n",
    "        \"data\": data,\n",
    "    })\n",
    "    headers = {\n",
    "        'Content-Type': 'application/json',\n",
    "    }\n",
    "    return requests.request(\"POST\", function_url, headers=headers, data=payload).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create variables to store function url and pipeline name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign `function_url_endpoint` your function url endpoint\n",
    "function_url_endpoint = \"https://yugkwzcne3rop4meh2x3g32xbq0fbhrp.lambda-url.us-east-1.on.aws/\"\n",
    "pipeline_name = \"sklearn-multimodel\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a test banknote data and invoke the `banknote-authentication` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banknote_testdata = [\n",
    "    [3.6216,8.6661,-2.8073,-0.44699],\n",
    "    [4.5459,8.1674,-2.4586,-1.4621],\n",
    "    [3.866,-2.6383,1.9242,0.10645],\n",
    "    [3.4566,9.5228,-4.0112,-3.5944],\n",
    "]\n",
    "dataset = \"banknote-authentication\"\n",
    "invoke_endpoint(function_url_endpoint, pipeline_name, dataset, banknote_testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a test breast cancer data and invoke the `breast-cancer` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dummay data\n",
    "breastcancer_testdata = [\n",
    "    [1]*30,\n",
    "    [0]*30,\n",
    "]\n",
    "dataset = \"breast-cancer\"\n",
    "invoke_endpoint(function_url_endpoint, pipeline_name, dataset, breastcancer_testdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clearing AWS Resources and Artifacts Created By Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use terraform to destroy most of the resources created in this guideline with the following command.\n",
    "```shell\n",
    "terraform destroy\n",
    "```\n",
    "However, this command won't delete following resources. You've to delete them manually. Automated deletion is not implemented for them to avoid accidental deletion and terraform won't be able to recreate model artifacts from pipeline run.\n",
    "- AWS ECR repository and images inside.\n",
    "- AWS S3 Bucket and model artifacts created by deployment lambda function.\n",
    "- AWS Sagemaker Model Packages in Model Registry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
